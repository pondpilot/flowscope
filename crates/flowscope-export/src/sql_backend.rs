//! SQL generation backend for browser/WASM export.
//!
//! Generates DDL + INSERT statements that can be executed by duckdb-wasm.

use crate::schema::{tables_ddl, views_ddl};
use crate::ExportError;
use flowscope_core::AnalyzeResult;

/// Export analysis result as SQL statements (DDL + INSERT).
///
/// Returns a string containing:
/// 1. CREATE TABLE statements
/// 2. CREATE VIEW statements
/// 3. INSERT statements for all data
///
/// This can be executed directly by duckdb-wasm in the browser.
pub fn export_sql(result: &AnalyzeResult) -> Result<String, ExportError> {
    let mut sql = String::with_capacity(64 * 1024); // Pre-allocate 64KB

    // DDL
    sql.push_str("-- FlowScope Export\n");
    sql.push_str("-- Generated by flowscope-export\n\n");
    sql.push_str("-- Tables\n");
    sql.push_str(tables_ddl());
    sql.push_str("\n-- Views\n");
    sql.push_str(views_ddl());
    sql.push_str("\n-- Data\n");

    // Data
    write_meta_sql(&mut sql);
    write_statements_sql(&mut sql, result);
    write_nodes_sql(&mut sql, result);
    write_edges_sql(&mut sql, result);
    write_issues_sql(&mut sql, result);
    write_schema_tables_sql(&mut sql, result);
    write_global_lineage_sql(&mut sql, result);

    Ok(sql)
}

/// Escape a string for SQL insertion (single quotes).
fn escape_sql(s: &str) -> String {
    s.replace('\'', "''")
}

/// Format an optional string as SQL literal.
fn sql_str(s: Option<&str>) -> String {
    match s {
        Some(v) => format!("'{}'", escape_sql(v)),
        None => "NULL".to_string(),
    }
}

/// Format an optional i64 as SQL literal.
fn sql_int(v: Option<i64>) -> String {
    match v {
        Some(n) => n.to_string(),
        None => "NULL".to_string(),
    }
}

/// Format a boolean as SQL literal.
fn sql_bool(v: bool) -> &'static str {
    if v {
        "TRUE"
    } else {
        "FALSE"
    }
}

/// Format an optional boolean as SQL literal.
fn sql_opt_bool(v: Option<bool>) -> &'static str {
    match v {
        Some(true) => "TRUE",
        Some(false) => "FALSE",
        None => "NULL",
    }
}

fn write_meta_sql(sql: &mut String) {
    let version = env!("CARGO_PKG_VERSION");
    let timestamp = chrono::Utc::now().to_rfc3339();

    sql.push_str(&format!(
        "INSERT INTO _meta (key, value) VALUES ('version', '{}');\n",
        escape_sql(version)
    ));
    sql.push_str(&format!(
        "INSERT INTO _meta (key, value) VALUES ('exported_at', '{}');\n",
        escape_sql(&timestamp)
    ));
}

fn write_statements_sql(sql: &mut String, result: &AnalyzeResult) {
    for (idx, s) in result.statements.iter().enumerate() {
        let (span_start, span_end) = s
            .span
            .map(|sp| (Some(sp.start as i64), Some(sp.end as i64)))
            .unwrap_or((None, None));

        sql.push_str(&format!(
            "INSERT INTO statements (id, statement_index, statement_type, source_name, span_start, span_end, join_count, complexity_score) VALUES ({}, {}, {}, {}, {}, {}, {}, {});\n",
            idx,
            s.statement_index,
            sql_str(Some(&s.statement_type)),
            sql_str(s.source_name.as_deref()),
            sql_int(span_start),
            sql_int(span_end),
            s.join_count,
            s.complexity_score,
        ));
    }
}

fn write_nodes_sql(sql: &mut String, result: &AnalyzeResult) {
    let mut join_id: i64 = 0;
    let mut filter_id: i64 = 0;

    for (stmt_idx, statement) in result.statements.iter().enumerate() {
        for node in &statement.nodes {
            let (span_start, span_end) = node
                .span
                .map(|sp| (Some(sp.start as i64), Some(sp.end as i64)))
                .unwrap_or((None, None));
            let node_type = format!("{:?}", node.node_type).to_lowercase();
            let resolution = node
                .resolution_source
                .map(|r| format!("{:?}", r).to_lowercase());

            sql.push_str(&format!(
                "INSERT INTO nodes (id, statement_id, node_type, label, qualified_name, expression, span_start, span_end, resolution_source) VALUES ({}, {}, {}, {}, {}, {}, {}, {}, {});\n",
                sql_str(Some(node.id.as_ref())),
                stmt_idx,
                sql_str(Some(&node_type)),
                sql_str(Some(node.label.as_ref())),
                sql_str(node.qualified_name.as_ref().map(|s| s.as_ref())),
                sql_str(node.expression.as_ref().map(|s| s.as_ref())),
                sql_int(span_start),
                sql_int(span_end),
                sql_str(resolution.as_deref()),
            ));

            // Write join info if present
            if let Some(join_type) = &node.join_type {
                let jt = format!("{:?}", join_type).to_uppercase();
                sql.push_str(&format!(
                    "INSERT INTO joins (id, node_id, join_type, join_condition) VALUES ({}, {}, {}, {});\n",
                    join_id,
                    sql_str(Some(node.id.as_ref())),
                    sql_str(Some(&jt)),
                    sql_str(node.join_condition.as_ref().map(|s| s.as_ref())),
                ));
                join_id += 1;
            }

            // Write filters
            for filter in &node.filters {
                let ft = format!("{:?}", filter.clause_type).to_lowercase();
                sql.push_str(&format!(
                    "INSERT INTO filters (id, node_id, predicate, filter_type) VALUES ({}, {}, {}, {});\n",
                    filter_id,
                    sql_str(Some(node.id.as_ref())),
                    sql_str(Some(&filter.expression)),
                    sql_str(Some(&ft)),
                ));
                filter_id += 1;
            }

            // Write aggregation info
            if let Some(agg) = &node.aggregation {
                sql.push_str(&format!(
                    "INSERT INTO aggregations (node_id, is_grouping_key, function, is_distinct) VALUES ({}, {}, {}, {});\n",
                    sql_str(Some(node.id.as_ref())),
                    sql_bool(agg.is_grouping_key),
                    sql_str(agg.function.as_deref()),
                    sql_opt_bool(agg.distinct),
                ));
            }
        }
    }
}

fn write_edges_sql(sql: &mut String, result: &AnalyzeResult) {
    let mut edge_id: i64 = 0;
    for (stmt_idx, statement) in result.statements.iter().enumerate() {
        for edge in &statement.edges {
            let edge_type = format!("{:?}", edge.edge_type).to_lowercase();
            sql.push_str(&format!(
                "INSERT INTO edges (id, statement_id, edge_type, from_node_id, to_node_id, expression, operation, is_approximate) VALUES ({}, {}, {}, {}, {}, {}, {}, {});\n",
                edge_id,
                stmt_idx,
                sql_str(Some(&edge_type)),
                sql_str(Some(edge.from.as_ref())),
                sql_str(Some(edge.to.as_ref())),
                sql_str(edge.expression.as_ref().map(|s| s.as_ref())),
                sql_str(edge.operation.as_ref().map(|s| s.as_ref())),
                sql_bool(edge.approximate.unwrap_or(false)),
            ));
            edge_id += 1;
        }
    }
}

fn write_issues_sql(sql: &mut String, result: &AnalyzeResult) {
    for (issue_id, issue) in result.issues.iter().enumerate() {
        let severity = format!("{:?}", issue.severity).to_lowercase();
        let (span_start, span_end) = issue
            .span
            .map(|sp| (Some(sp.start as i64), Some(sp.end as i64)))
            .unwrap_or((None, None));

        sql.push_str(&format!(
            "INSERT INTO issues (id, statement_id, severity, code, message, span_start, span_end) VALUES ({}, {}, {}, {}, {}, {}, {});\n",
            issue_id,
            sql_int(issue.statement_index.map(|i| i as i64)),
            sql_str(Some(&severity)),
            sql_str(Some(&issue.code)),
            sql_str(Some(&issue.message)),
            sql_int(span_start),
            sql_int(span_end),
        ));
    }
}

fn write_schema_tables_sql(sql: &mut String, result: &AnalyzeResult) {
    let Some(schema) = &result.resolved_schema else {
        return;
    };

    let mut col_id: i64 = 0;
    for (table_id, table) in schema.tables.iter().enumerate() {
        let origin = format!("{:?}", table.origin).to_lowercase();
        sql.push_str(&format!(
            "INSERT INTO schema_tables (id, catalog, schema_name, name, resolution_source) VALUES ({}, {}, {}, {}, {});\n",
            table_id,
            sql_str(table.catalog.as_deref()),
            sql_str(table.schema.as_deref()),
            sql_str(Some(&table.name)),
            sql_str(Some(&origin)),
        ));

        for col in &table.columns {
            sql.push_str(&format!(
                "INSERT INTO schema_columns (id, table_id, name, data_type, is_nullable, is_primary_key) VALUES ({}, {}, {}, {}, {}, {});\n",
                col_id,
                table_id,
                sql_str(Some(&col.name)),
                sql_str(col.data_type.as_deref()),
                "NULL", // is_nullable not in current schema
                sql_opt_bool(col.is_primary_key),
            ));
            col_id += 1;
        }
    }
}

fn write_global_lineage_sql(sql: &mut String, result: &AnalyzeResult) {
    let mut ref_id: i64 = 0;

    for node in &result.global_lineage.nodes {
        let node_type = format!("{:?}", node.node_type).to_lowercase();
        let resolution = node
            .resolution_source
            .map(|r| format!("{:?}", r).to_lowercase());

        sql.push_str(&format!(
            "INSERT INTO global_nodes (id, node_type, label, canonical_catalog, canonical_schema, canonical_name, canonical_column, resolution_source) VALUES ({}, {}, {}, {}, {}, {}, {}, {});\n",
            sql_str(Some(node.id.as_ref())),
            sql_str(Some(&node_type)),
            sql_str(Some(node.label.as_ref())),
            sql_str(node.canonical_name.catalog.as_deref()),
            sql_str(node.canonical_name.schema.as_deref()),
            sql_str(Some(&node.canonical_name.name)),
            sql_str(node.canonical_name.column.as_deref()),
            sql_str(resolution.as_deref()),
        ));

        for stmt_ref in &node.statement_refs {
            sql.push_str(&format!(
                "INSERT INTO global_node_statement_refs (id, global_node_id, statement_index, local_node_id) VALUES ({}, {}, {}, {});\n",
                ref_id,
                sql_str(Some(node.id.as_ref())),
                stmt_ref.statement_index,
                sql_str(stmt_ref.node_id.as_ref().map(|s| s.as_ref())),
            ));
            ref_id += 1;
        }
    }

    for edge in &result.global_lineage.edges {
        let edge_type = format!("{:?}", edge.edge_type).to_lowercase();
        sql.push_str(&format!(
            "INSERT INTO global_edges (id, from_node_id, to_node_id, edge_type) VALUES ({}, {}, {}, {});\n",
            sql_str(Some(edge.id.as_ref())),
            sql_str(Some(edge.from.as_ref())),
            sql_str(Some(edge.to.as_ref())),
            sql_str(Some(&edge_type)),
        ));
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use flowscope_core::{analyze, AnalyzeRequest, Dialect};

    #[test]
    fn test_escape_sql() {
        assert_eq!(escape_sql("hello"), "hello");
        assert_eq!(escape_sql("it's"), "it''s");
        assert_eq!(escape_sql("a'b'c"), "a''b''c");
    }

    #[test]
    fn test_sql_str() {
        assert_eq!(sql_str(Some("hello")), "'hello'");
        assert_eq!(sql_str(Some("it's")), "'it''s'");
        assert_eq!(sql_str(None), "NULL");
    }

    #[test]
    fn test_export_sql_empty_result() {
        let result = AnalyzeResult::default();
        let sql = export_sql(&result).expect("Export should succeed");
        assert!(sql.contains("CREATE TABLE _meta"));
        assert!(sql.contains("CREATE VIEW column_lineage"));
        assert!(sql.contains("INSERT INTO _meta"));
    }

    #[test]
    fn test_export_sql_simple_query() {
        let request = AnalyzeRequest {
            sql: "SELECT id, name FROM users WHERE active = true".to_string(),
            files: None,
            dialect: Dialect::Generic,
            source_name: None,
            options: None,
            schema: None,
        };
        let result = analyze(&request);
        let sql = export_sql(&result).expect("Export should succeed");

        // Should contain DDL
        assert!(sql.contains("CREATE TABLE statements"));
        assert!(sql.contains("CREATE TABLE nodes"));

        // Should contain data
        assert!(sql.contains("INSERT INTO statements"));
        assert!(sql.contains("INSERT INTO nodes"));
    }

    #[test]
    fn test_export_sql_escapes_quotes() {
        let request = AnalyzeRequest {
            sql: "SELECT 'it''s a test' AS msg".to_string(),
            files: None,
            dialect: Dialect::Generic,
            source_name: None,
            options: None,
            schema: None,
        };
        let result = analyze(&request);
        let sql = export_sql(&result).expect("Export should succeed");

        // SQL should be valid (no unescaped quotes breaking statements)
        assert!(!sql.contains("'it's")); // Should be escaped
    }
}
